{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EOF Analysis of SALLJ days\n",
    "\n",
    "* Multivariate EOF analysis in T-mode\n",
    "* K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python modules\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as  pd\n",
    "import xarray as xr\n",
    "from sklearn.cluster import KMeans\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import rcParams\n",
    "# cartopy\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "# plot styles/formatting\n",
    "import seaborn as sns\n",
    "import cmocean.cm as cmo\n",
    "import cmocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to module directory\n",
    "sys.path.append('/home/sbarc/students/montini/repos/sallj-types/modules/')\n",
    "\n",
    "# Import my modules\n",
    "from plotter import draw_basemap\n",
    "from timeseries import persistence\n",
    "from eofs import *\n",
    "#from kmeans import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "\n",
    "home = Path.home()                     # users home directory\n",
    "root = home/'repos'/'sallj-types'  # project root directory\n",
    "path_to_data = root/'data'           # project data -- read only\n",
    "path_to_out  = root/'out'             # output files (numerical results, intermediate datafiles) -- read & write\n",
    "path_to_figs = root/'figs'           # figures\n",
    "\n",
    "# check that path exists\n",
    "path_to_figs.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a default font for all matplotlib text (can only set this ONCE; must restart kernel to change it)\n",
    "\n",
    "rcParams['font.family'] = 'sans-serif'   # set the default font family to 'sans-serif'\n",
    "rcParams['font.sans-serif'] = 'Arial'    # set the default sans-serif font to 'Arial'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SALLJ time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV data into pandas DataFrame\n",
    "filepath = path_to_data / 'erai.llj.day.1979-2016.csv'\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "# Add datetime column\n",
    "df['dates'] = pd.date_range(start='1979-01-01',end='2016-12-31',freq='D')\n",
    "# Set the index to `dates`\n",
    "df.set_index('dates', inplace=True)\n",
    "\n",
    "# Add column of LLJ days (no LLJ day eq 0; LLJ day eq 1)\n",
    "df['llj'] = 0\n",
    "idx = (df['llj_sc'] > 0) | (df['llj_ma'] > 0)\n",
    "df.loc[idx, 'llj'] = 1\n",
    "\n",
    "# Add column of LLJ locations ('SC', 'MA', 'SC/MA', nan)\n",
    "df['location'] = np.nan\n",
    "\n",
    "idx = (df['llj_sc'] == 1) & (df['llj_ma'] == 0)\n",
    "df.loc[idx, 'location'] = 'SC'\n",
    "\n",
    "idx = (df['llj_sc'] == 0) & (df['llj_ma'] == 1)\n",
    "df.loc[idx, 'location'] = 'MA'\n",
    "\n",
    "idx = (df['llj_sc'] == 1) & (df['llj_ma'] == 1)\n",
    "df.loc[idx, 'location'] = 'SC/MA'\n",
    "\n",
    "# Show table\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ERA5 reanalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datafiles into xarray datasets\n",
    "f1 = xr.open_dataset(path_to_data/'era5.sam.05dg.ivte.1979-2016.nc')\n",
    "f2 = xr.open_dataset(path_to_data/'era5.sam.05dg.ivtn.1979-2016.nc')\n",
    "\n",
    "# Merge variables into one dataset\n",
    "era = xr.merge([f1,f2])\n",
    "\n",
    "# Add LLJ time series to era5; set as coordinate variables\n",
    "era['llj'] = ('time', df.llj)\n",
    "era = era.set_coords('llj')\n",
    "\n",
    "era['location'] = ('time', df.location)\n",
    "era = era.set_coords('location')\n",
    "\n",
    "# print dataset\n",
    "print(era)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Subset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim date range\n",
    "start_date = '1979-11-01'\n",
    "end_date = '2016-03-31'\n",
    "idx = slice(start_date, end_date)\n",
    "era = era.sel(time=idx)\n",
    "\n",
    "# Select NDJFM months\n",
    "idx = (era.time.dt.month >= 11) | (era.time.dt.month <= 3)\n",
    "era = era.sel(time=idx)\n",
    "\n",
    "# Select lat/lon grid\n",
    "lonmin = -83\n",
    "lonmax = -32\n",
    "latmin = -47\n",
    "latmax =  10\n",
    "era = era.sel(longitude=slice(lonmin,lonmax), latitude=slice(latmax,latmin))\n",
    "\n",
    "# Select LLJ days\n",
    "idx = (era.llj >= 1)\n",
    "era_llj = era.sel(time=idx)\n",
    "\n",
    "# print results\n",
    "print(era_llj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of independent LLJ events\n",
    "\n",
    "years = np.arange(1979, 2017) \n",
    "nyrs = len(years)\n",
    "total_events = 0\n",
    "for k in range(nyrs-1):    \n",
    "    # Extract single NDJFM season\n",
    "    date1 = \"{}-11-01\".format(years[k])\n",
    "    date2 = \"{}-03-31\".format(years[k+1])\n",
    "    x = era.llj.sel(time=slice(date1,date2)).values\n",
    "    # Count LLJ events in that season\n",
    "    tags, tmp = persistence(x)\n",
    "    # Add to running event count\n",
    "    total_events += tmp\n",
    "\n",
    "print(\"Number of independent LLJ events: \", total_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climatology and Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean IVT of LLJ days in NDJFM\n",
    "era_llj_clim = era_llj.mean(dim='time')\n",
    "#print(era_llj_clim, '\\n')\n",
    "\n",
    "# IVT Anomalies\n",
    "era_llj['ivte_anom'] = era_llj.ivte - era_llj_clim.ivte\n",
    "era_llj['ivtn_anom'] = era_llj.ivtn - era_llj_clim.ivtn\n",
    "#print(era_llj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape, center, and standardize data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract variables as numpy arrays\n",
    "var1 = era_llj.ivte_anom.values\n",
    "var2 = era_llj.ivtn_anom.values\n",
    "\n",
    "# Data dimensions\n",
    "ntim = var1.shape[0]\n",
    "nlat = var1.shape[1]\n",
    "nlon = var1.shape[2]\n",
    "npts = nlat*nlon\n",
    "nvar = 2\n",
    "\n",
    "# Reshape into 2D arrays by flattening the spatial dimension\n",
    "tmp1 = np.reshape(var1, (ntim, npts))\n",
    "tmp2 = np.reshape(var2, (ntim, npts))\n",
    "\n",
    "# Transpose arrays to get [space x time]\n",
    "X1 = tmp1.T\n",
    "X2 = tmp2.T\n",
    "\n",
    "# Center and standardize by columns\n",
    "x1mean = np.mean(X1, axis=0)\n",
    "x1std = np.std(X1, axis=0)\n",
    "X1s = (X1-x1mean) / x1std\n",
    "\n",
    "x2mean = np.mean(X2, axis=0)\n",
    "x2std = np.std(X2, axis=0)\n",
    "X2s = (X2-x2mean) / x2std\n",
    "\n",
    "# Combine variables into single data matrix Xs\n",
    "Xs = np.empty((nvar*npts,ntim))\n",
    "Xs[0:npts,:] = X1s\n",
    "Xs[npts:,:]  = X2s\n",
    "print(Xs.shape)\n",
    "\n",
    "# Check that column means=0 and std dev=1\n",
    "test = np.mean(np.mean(Xs, axis=0))\n",
    "print(\"Column means: \", np.round(test,2))\n",
    "test = np.mean(np.std(Xs, axis=0))\n",
    "print(\"Column std: \", np.round(test,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EOF Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute eigenvalues & eigenvectors\n",
    "evals, evecs = calc_eofs(Xs)\n",
    "\n",
    "print('Eigenvalues: ', evals.shape)\n",
    "print(evals, '\\n')\n",
    "\n",
    "print('Eigenvectors: ', evecs.shape)\n",
    "print(np.round(evecs, 3), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explained Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percent explained var by each eigenvector\n",
    "pctvar = pct_variance(evals)\n",
    "\n",
    "# Number of EOFs that explain more than 1% of the total variance\n",
    "idx = pctvar[pctvar >= 1.0]\n",
    "neofs = len(idx)\n",
    "\n",
    "# print exp var >= 1.0\n",
    "cumvar = np.sum(pctvar[0:neofs-1])\n",
    "print(f'Cumulative variance explained by the first {neofs} EOFs:')\n",
    "print(f'{cumvar:.2f}% \\n')\n",
    "\n",
    "# print exp var: neofs = 4\n",
    "cumvar = np.sum(pctvar[0:3])\n",
    "print(f'Cumulative variance explained by the first 4 EOFs:')\n",
    "print(f'{cumvar:.2f}% \\n')\n",
    "\n",
    "# print exp var for 4 eofs\n",
    "for k in range(4):\n",
    "    print(f'{k+1} \\t {pctvar[k]:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### North Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = north_test(evals, total_events)\n",
    "upper = pctvar + err\n",
    "lower = pctvar - err\n",
    "\n",
    "print(np.round(upper[0:6],3))\n",
    "print(np.round(pctvar[0:6],3))\n",
    "print(np.round(lower[0:6],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 2: Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seaborn style\n",
    "sns.set()\n",
    "sns.set_style(\"ticks\", {'patch.force_edgecolor':False})\n",
    "\n",
    "# create figure\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "\n",
    "# plot data\n",
    "xvals = np.arange(neofs) + 1\n",
    "ax.bar(xvals, pctvar[0:neofs], yerr=err[0:neofs], \n",
    "       color='tab:blue', alpha=0.8)\n",
    "\n",
    "# x-axis\n",
    "ax.set_xlabel('EOF')\n",
    "ax.set_xticks(xvals)\n",
    "\n",
    "# y-axis\n",
    "ax.set_ylabel('Explained Variance (%)')\n",
    "yticks = np.arange(0,16,3)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(yticks) \n",
    "\n",
    "# save fig\n",
    "filepath = path_to_figs / 'fig2.png'\n",
    "plt.savefig(filepath, dpi=300)\n",
    "\n",
    "# show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neofs = 19\n",
    "loads = loadings(evals, evecs, neofs)\n",
    "\n",
    "print(loads.shape)\n",
    "print(np.round(loads,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save EOFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save eigenvalues, eigenvectors, and loadings\n",
    "\n",
    "neofs = 4   # number of EOFs to save (evecs, loadings3)\n",
    "\n",
    "outfile = path_to_out / 'eigenvalues.txt'\n",
    "np.savetxt(outfile, evals, fmt='%.5f')\n",
    "\n",
    "outfile = path_to_out / 'eigenvectors.txt'\n",
    "np.savetxt(outfile, evecs[:,0:neofs], fmt='%.5f', delimiter=',')\n",
    "\n",
    "outfile = path_to_out / 'loadings.txt'\n",
    "np.savetxt(outfile, loads[:,0:neofs], fmt='%.4f', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate principal components (spatial modes)\n",
    "pcs = calc_pcs(Xs, evecs, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split pcs into separate arrays for each variable\n",
    "tmp1 = pcs[:,0:npts]\n",
    "tmp2 = pcs[:,npts:]\n",
    "\n",
    "# Reshape spatial dim back to 2D map\n",
    "neofs=19\n",
    "pcmodes_var1 = np.reshape(tmp1, (neofs,nlat,nlon))\n",
    "pcmodes_var2 = np.reshape(tmp2, (neofs,nlat,nlon))\n",
    "#print(pcmodes_var1.shape, pcmodes_var2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 3: Spatial Modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel Plot of Spatial Modes\n",
    "\n",
    "# number of eofs to plot\n",
    "neofs = 4\n",
    "\n",
    "# Data for plotting\n",
    "lons = era_llj.longitude.data\n",
    "lats = era_llj.latitude.data\n",
    "udat = pcmodes_var1[0:neofs,:,:]\n",
    "vdat = pcmodes_var2[0:neofs,:,:]\n",
    "data = np.sqrt(udat**2 + vdat**2)\n",
    "#print(data.min(), data.max())\n",
    "\n",
    "# Set up projection\n",
    "mapcrs = ccrs.PlateCarree()\n",
    "datacrs = ccrs.PlateCarree()\n",
    "\n",
    "# Set tick/grid locations\n",
    "dx = np.arange(-80,lonmax,20)\n",
    "dy = np.arange(-40,latmax,20)\n",
    "\n",
    "# subtitles\n",
    "eof_label = [ ]\n",
    "var_label = [ ]\n",
    "for k in range(neofs):\n",
    "    eof_label.append(\"EOF{:1d}\".format(k+1,))\n",
    "    var_label.append(\"{:.2f}%\".format(pctvar[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig = plt.figure(figsize=(10,11))\n",
    "nrows = 2\n",
    "ncols = 2\n",
    "\n",
    "sns.set_style('ticks')\n",
    "\n",
    "# Set up Axes Grid\n",
    "axes_class = (GeoAxes,dict(map_projection=mapcrs))\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "                nrows_ncols=(nrows, ncols), axes_pad = 0.55,\n",
    "                cbar_location='bottom', cbar_mode='single',\n",
    "                cbar_pad=0.0, cbar_size='2.5%',label_mode='')\n",
    "\n",
    "#newcmap = cmocean.tools.crop_by_percent(cmo.matter, 15, which='max', N=None)\n",
    "\n",
    "# Loop for drawing each plot\n",
    "for k, ax in enumerate(axgr):\n",
    "    ax = draw_basemap(ax, extent=[lonmin,lonmax,latmin,latmax], xticks=dx, yticks=dy)\n",
    "    \n",
    "    # Add contour fill plot\n",
    "    clevs = np.arange(0,71,5)\n",
    "    cf = ax.contourf(lons, lats, data[k,:,:], transform=datacrs,\n",
    "                     levels=clevs,cmap=\"Blues\")\n",
    "    # add vectors\n",
    "    ax.quiver(lons, lats, udat[k,:,:], vdat[k,:,:], transform=datacrs,\n",
    "              color='black', pivot='middle', regrid_shape=20)      \n",
    "    # subtitles\n",
    "    ax.set_title(eof_label[k], loc='left', fontsize=12)\n",
    "    ax.set_title(var_label[k], loc='right', fontsize=12)\n",
    "    \n",
    "# single colorbar\n",
    "cb = fig.colorbar(cf, axgr.cbar_axes[0], orientation='horizontal', drawedges=True)\n",
    "cb.set_label('kg m$^{-1}$ s$^{-1}$', fontsize=11)\n",
    "cb.ax.tick_params(labelsize=10)\n",
    "    \n",
    "# Display figure\n",
    "filepath = home/'Desktop' / 'eofs.png'\n",
    "plt.savefig(filepath, dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine optimal K\n",
    "\n",
    "# maximum number of clusters (number of iterations)\n",
    "kmax =15\n",
    "# number of eofs\n",
    "neofs = 4\n",
    "# input data\n",
    "xdata = loads[:,0:neofs]\n",
    "\n",
    "# Elbow plot\n",
    "outfile = home/'Desktop' / 'xfig1.png'\n",
    "plot_optimal_k(xdata, kmax, filename=outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K-means cluster analysis\n",
    "\n",
    "# Number of clusters\n",
    "nk = 4\n",
    "\n",
    "# Input data\n",
    "xdata = loads[:,0:neofs]\n",
    "\n",
    "# Compute k means and assign each point to a cluster\n",
    "kmeans = KMeans(n_clusters=nk)\n",
    "kmeans.fit(xdata)\n",
    "cluster = kmeans.predict(xdata)\n",
    "\n",
    "# LLJ category labels (llj days only)\n",
    "llj_cat = cluster + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of days in each cluster\n",
    "klabels, counts = np.unique(llj_cat, return_counts=True)\n",
    "\n",
    "# Save counts to txt file\n",
    "res = np.column_stack((klabels,counts))\n",
    "headstr = 'LLJ_TYPE, COUNT'\n",
    "outfile = path_to_out / 'k_counts.txt'\n",
    "np.savetxt(outfile, res, delimiter=',', fmt='%d', header=headstr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster centroids (nclust x neofs)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Save centroids to txt file\n",
    "res = np.column_stack((klabels,centroids))\n",
    "headstr = \"LLJ_TYPE, EOF1, EOF2, EOF3, EOF4\"\n",
    "outfile = path_to_out / 'centroids.txt'\n",
    "np.savetxt(outfile, res, delimiter=',', fmt='%s', header=headstr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save LLJ category labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save LLJ location, loadings (EOF1-4), and category label (LLJ days only)\n",
    "\n",
    "# Vector of LLJ dates\n",
    "dates_lljDays = era_llj.time.values\n",
    "\n",
    "# Create new dataframe\n",
    "data = {'LOC':era_llj.location.values,\n",
    "        'EOF1':loads[:,0],\n",
    "        'EOF2':loads[:,1],\n",
    "        'EOF3':loads[:,2],\n",
    "        'EOF4':loads[:,3],\n",
    "        'LLJ_CAT':llj_cat}\n",
    "df_out = pd.DataFrame(data, index=dates_lljDays)\n",
    "print(df_out)\n",
    "\n",
    "# Export dataframe as csv\n",
    "outfile = path_to_out / 'sallj-types-loadings.csv'\n",
    "df_out.to_csv(outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save time series of all NDJFM days with SALLJ types\n",
    "\n",
    "# Arrays with ALL NDJFM days\n",
    "dates_allDays = era.time.values\n",
    "llj_cat_allDays = np.zeros(len(dates_allDays), dtype=int)\n",
    "\n",
    "# Loop over llj days and match to llj_full \n",
    "for i, date in enumerate(dates_lljDays):\n",
    "    idx = np.where(dates_allDays == date)\n",
    "    llj_cat_allDays[idx] = llj_cat[i]  \n",
    "\n",
    "# Create dataframe\n",
    "data = {'LLJ_CAT':llj_cat_allDays}\n",
    "df_out = pd.DataFrame(data, index=dates_allDays)\n",
    "print(df_out)\n",
    "\n",
    "outfile = path_to_out / 'sallj-types-ndjfm.csv'\n",
    "df_out.to_csv(outfile)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyclivac)",
   "language": "python",
   "name": "pyclivac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "191.59375px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
