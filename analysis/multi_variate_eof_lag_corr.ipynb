{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python modules\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as  pd\n",
    "import xarray as xr\n",
    "from sklearn.cluster import KMeans\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.ticker as mticker\n",
    "# cartopy\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import cartopy.feature as cfeature\n",
    "# plot styles/formatting\n",
    "import seaborn as sns\n",
    "import cmocean.cm as cmo\n",
    "import cmocean\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Path to modules\n",
    "sys.path.append('../modules')\n",
    "\n",
    "# Import my modules\n",
    "from plotter import draw_basemap\n",
    "from timeseries import persistence\n",
    "from eofs import *\n",
    "from ar_funcs import preprocess_ar_area_subregions\n",
    "from kmeans import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "\n",
    "path_to_data = '/home/nash/DATA/data/'                            # project data -- read only\n",
    "path_to_out  = '/home/nash/DATA/repositories/AR_types/out/'       # output files (numerical results, intermediate datafiles) -- read & write\n",
    "path_to_figs = '/home/nash/DATA/repositories/AR_types/figs/cEOF_tropics_extratropics/'      # figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a default font for all matplotlib text (can only set this ONCE; must restart kernel to change it)\n",
    "\n",
    "rcParams['font.family'] = 'sans-serif'   # set the default font family to 'sans-serif'\n",
    "rcParams['font.sans-serif'] = 'Arial'    # set the default sans-serif font to 'Arial'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AR time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R01</th>\n",
       "      <th>R02</th>\n",
       "      <th>R03</th>\n",
       "      <th>ar</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979-01-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-01-02</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-01-03</th>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-01-04</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-01-05</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 R01  R02  R03  ar location\n",
       "time                                       \n",
       "1979-01-01  0.000000  0.0  0.0   0      NaN\n",
       "1979-01-02  0.000000  0.0  0.0   0      NaN\n",
       "1979-01-03  0.005102  0.0  0.0   0      NaN\n",
       "1979-01-04  0.000000  0.0  0.0   0      NaN\n",
       "1979-01-05  0.000000  0.0  0.0   0      NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Select MERRA2 or ERA5\n",
    "reanalysis = 'era5'\n",
    "\n",
    "if reanalysis == 'era5':\n",
    "    start_date = '1979-01-01'\n",
    "    end_date = '2018-12-31'\n",
    "    filename = 'ar_catalog_ERAI_fraction_HASIAsubregions.nc'\n",
    "## if MERRA2\n",
    "else:\n",
    "    start_date = '1980-01-01'\n",
    "    end_date = '2017-12-31'\n",
    "    filename = 'ar_catalog_fraction_HASIAsubregions.nc'\n",
    "    \n",
    "f1 = path_to_data + 'CH1_generated_data/' + filename\n",
    "ds = xr.open_dataset(f1)\n",
    "# Set dates\n",
    "ds = ds.sel(time=slice(start_date, end_date))\n",
    "## Preprocess AR subregions - get dataframe of AR days based on area threshold\n",
    "df = preprocess_ar_area_subregions(df=ds.to_dataframe(), thres=0.3)\n",
    "# Show table\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import reanalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds size in GB 36.28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Set variable names (for saving data/figs)\n",
    "var_names = 'HUV250QUV850'\n",
    "eofmode = 't' # s or t\n",
    "dispmat = 'cor' # dispersion matrix type correlation/covariance\n",
    "\n",
    "# Select lat/lon grid \n",
    "# Tropics/Extratropics Domain\n",
    "lonmin = 0\n",
    "lonmax = 120\n",
    "latmin = -15\n",
    "latmax = 65\n",
    "\n",
    "lev = [850., 250.]\n",
    "\n",
    "# for figure names for testing different configurations\n",
    "fname_id = var_names + eofmode + str(lonmin) + str(lonmax) + str(latmin) + str(latmax) + dispmat\n",
    "\n",
    "def preprocess(ds):\n",
    "    '''keep only selected lats and lons'''\n",
    "    return ds.sel(latitude=slice(latmax, latmin), longitude=slice(lonmin, lonmax), level=lev)\n",
    "\n",
    "# open HUV anomaly data\n",
    "filepath_pattern = path_to_data + 'ERA5/huvq/anomalies/daily_filtered_anomalies_huvq_*.nc'\n",
    "    \n",
    "    \n",
    "f2 = xr.open_mfdataset(filepath_pattern, preprocess=preprocess, combine='by_coords')\n",
    "\n",
    "# Create new dataset to rename lat lon\n",
    "ds = xr.Dataset({'H': (['time', 'level', 'lat', 'lon'], f2['z'].values),\n",
    "                 'U': (['time', 'level',  'lat', 'lon'], f2['u'].values),\n",
    "                 'V': (['time', 'level',  'lat', 'lon'], f2['v'].values),\n",
    "                 'QV': (['time', 'level',  'lat', 'lon'], f2['q'].values)},\n",
    "                      coords={'time': (['time'], f2.time.values),\n",
    "                              'level': (['level'], f2.level.values),\n",
    "                              'lat': (['lat'], f2.latitude.values),\n",
    "                              'lon': (['lon'], f2.longitude.values)})\n",
    "\n",
    "ds\n",
    "print('ds size in GB {:0.2f}\\n'.format(ds.nbytes / 1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:   (lat: 161, level: 2, lon: 241, time: 14610)\n",
      "Coordinates:\n",
      "  * time      (time) datetime64[ns] 1979-01-01T09:00:00 ... 2018-12-31T09:00:00\n",
      "  * level     (level) float64 850.0 250.0\n",
      "  * lat       (lat) float32 65.0 64.5 64.0 63.5 63.0 ... -13.5 -14.0 -14.5 -15.0\n",
      "  * lon       (lon) float32 0.0 0.5 1.0 1.5 2.0 ... 118.5 119.0 119.5 120.0\n",
      "    ar        (time) int64 0 0 0 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "    location  (time) object nan nan nan nan nan nan ... nan nan nan nan nan nan\n",
      "Data variables:\n",
      "    H         (time, level, lat, lon) float64 931.6 945.5 956.6 ... 421.8 425.2\n",
      "    U         (time, level, lat, lon) float64 -8.089 -7.954 ... -10.98 -11.09\n",
      "    V         (time, level, lat, lon) float64 6.575 6.285 ... -1.857 -1.946\n",
      "    QV        (time, level, lat, lon) float64 -0.001679 -0.001712 ... 0.0001567\n"
     ]
    }
   ],
   "source": [
    "# Add AR time series to merra; set as coordinate variables\n",
    "ds['ar'] = ('time', df.ar)\n",
    "ds = ds.set_coords('ar')\n",
    "\n",
    "ds['location'] = ('time', df.location)\n",
    "ds = ds.set_coords('location')\n",
    "\n",
    "# print dataset\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Subset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 8.45 GiB for an array with shape (14610, 2, 161, 241) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bae82e92e321>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mar\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mds_shift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# ds_ar = ds.sel(time=idx.shift(time = -2).dropna(dim='time'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sbarc/students/nash/anaconda3/envs/ar_types/lib/python3.7/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mshift\u001b[0;34m(self, shifts, fill_value, **shifts_kwargs)\u001b[0m\n\u001b[1;32m   5033\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5034\u001b[0m                 \u001b[0mvar_shifts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshifts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5035\u001b[0;31m                 \u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshifts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar_shifts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5036\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5037\u001b[0m                 \u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sbarc/students/nash/anaconda3/envs/ar_types/lib/python3.7/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36mshift\u001b[0;34m(self, shifts, fill_value, **shifts_kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshifts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shift_one_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sbarc/students/nash/anaconda3/envs/ar_types/lib/python3.7/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36m_shift_one_dim\u001b[0;34m(self, dim, count, fill_value)\u001b[0m\n\u001b[1;32m   1108\u001b[0m             \u001b[0mpads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"constant\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0mconstant_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         )\n\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sbarc/students/nash/anaconda3/envs/ar_types/lib/python3.7/site-packages/xarray/core/duck_array_ops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meager_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpad\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/home/sbarc/students/nash/anaconda3/envs/ar_types/lib/python3.7/site-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0;31m# Create array with final shape and original values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;31m# (padded area is undefined)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_area_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pad_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m     \u001b[0;31m# And prepare iteration over all dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m     \u001b[0;31m# (zipping may be more readable than using enumerate)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sbarc/students/nash/anaconda3/envs/ar_types/lib/python3.7/site-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36m_pad_simple\u001b[0;34m(array, pad_width, fill_value)\u001b[0m\n\u001b[1;32m    114\u001b[0m     )\n\u001b[1;32m    115\u001b[0m     \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'F'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfnc\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'C'\u001b[0m  \u001b[0;31m# Fortran and not also C-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 8.45 GiB for an array with shape (14610, 2, 161, 241) and data type float64"
     ]
    }
   ],
   "source": [
    "# # Select AR days JUST IN R01\n",
    "# idx = (ds.ar >= 1) & (ds.location == 'R01')\n",
    "# Select AR days in all subregions\n",
    "idx = (ds.ar >= 1)\n",
    "\n",
    "ds_shift = ds.shift(time=-2).dropna(dim='time')\n",
    "\n",
    "# ds_ar = ds.sel(time=idx.shift(time = -2).dropna(dim='time'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim date range\n",
    "if reanalysis == 'era5':\n",
    "    start_date = '1979-12-01'\n",
    "    end_date = '2018-02-28'\n",
    "    ys = 1979\n",
    "    ye = 2018\n",
    "else:\n",
    "    start_date = '1980-12-01'\n",
    "    end_date = '2017-02-28'\n",
    "    ys = 1980\n",
    "    ye = 2017\n",
    "    \n",
    "idx = slice(start_date, end_date)\n",
    "ds = ds.sel(time=idx)\n",
    "\n",
    "# Select DJF months\n",
    "idx = (ds.time.dt.month >= 12) | (ds.time.dt.month <= 2)\n",
    "ds = ds.sel(time=idx)\n",
    "\n",
    "# # Select AR days JUST IN R01\n",
    "# idx = (ds.ar >= 1) & (ds.location == 'R01')\n",
    "# Select AR days in all subregions\n",
    "idx = (ds.ar >= 1)\n",
    "idx\n",
    "# ds_ar = ds.sel(time=idx)\n",
    "\n",
    "# # print results\n",
    "# print(ds_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_shift = idx.shift(time = -2)\n",
    "idx_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ar = ds.sel(time=idx_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_shift.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of independent AR events\n",
    "\n",
    "years = np.arange(ys, ye) \n",
    "nyrs = len(years)\n",
    "total_events = 0\n",
    "for k in range(nyrs-1):    \n",
    "    # Extract single DJF season\n",
    "    date1 = \"{}-12-01\".format(years[k])\n",
    "    date2 = \"{}-02-28\".format(years[k+1])\n",
    "    x = ds.ar.sel(time=slice(date1,date2)).values\n",
    "    # Count AR events in that season\n",
    "    tags, tmp = persistence(x)\n",
    "    # Add to running event count\n",
    "    total_events += tmp\n",
    "\n",
    "print(\"Number of independent AR events: \", total_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import HMA loadings s-mode correlation matrix\n",
    "filename = path_to_out + 'loadings_HUVQ500s0120-1565cor.txt'\n",
    "col_names = ['PC1', 'PC2', 'PC3', 'PC4']\n",
    "df1 = pd.read_csv(filename, header=None, names=col_names)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evecs = df1.to_numpy()\n",
    "evecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EOF represented as correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put PCS into dataset object\n",
    "npcs = 2\n",
    "ds_pc = xr.Dataset({'pc': (['time', 'pcs'], evecs[:,0:npcs])},\n",
    "                      coords={'time': (['time'], ds_ar.time.values),\n",
    "                              'pcs': (['pcs'], np.arange(npcs))})\n",
    "\n",
    "# select the pc to correlate\n",
    "pc1 = ds_pc.pc.sel(pcs=0)\n",
    "pc2 = ds_pc.pc.sel(pcs=1)\n",
    "# calculate statistics between AR ds and PCs\n",
    "cor1, pval1, tstat1 = correlation_pvalue(x=pc1, y=ds_ar, n=total_events)\n",
    "cor2, pval2, tstat2 = correlation_pvalue(x=pc2, y=ds_ar, n=total_events)\n",
    "\n",
    "# ## combine cor1 and cor2 into 1 ds object\n",
    "ds_cor = xr.concat([cor1, cor2], dim='pcs')\n",
    "ds_pval = xr.concat([pval1, pval2], dim='pcs')\n",
    "ds_tstat = xr.concat([tstat1, tstat2], dim='pcs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel Plot of Spatial Modes\n",
    "\n",
    "# number of eofs to plot\n",
    "neofs = 2\n",
    "\n",
    "# Data for plotting extratropics\n",
    "lons = ds_ar.lon.data\n",
    "lats = ds_ar.lat.data\n",
    "\n",
    "# Set up projection\n",
    "mapcrs = ccrs.PlateCarree()\n",
    "datacrs = ccrs.PlateCarree()\n",
    "\n",
    "# Set tick/grid locations\n",
    "dx = np.arange(lonmin,lonmax+20,20)\n",
    "dy = np.arange(latmin,latmax+20,20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig = plt.figure(figsize=(10,11))\n",
    "filepath = path_to_figs + 'cors_ivt'+ fname_id + '.png'\n",
    "nrows = 2\n",
    "ncols = 1\n",
    "# sns.set_style('ticks')\n",
    "eof_label = ['EOF1', 'EOF2', 'EOF3', 'EOF4']\n",
    "# Set up Axes Grid\n",
    "axes_class = (GeoAxes,dict(map_projection=mapcrs))\n",
    "axgr = AxesGrid(fig, \n",
    "                111, \n",
    "                axes_class=axes_class,\n",
    "                nrows_ncols=(nrows, ncols), \n",
    "                axes_pad = 0.55,\n",
    "                cbar_location='bottom', \n",
    "                cbar_mode='single',\n",
    "                cbar_pad=0.0, \n",
    "                cbar_size='2.5%',\n",
    "                label_mode='')\n",
    "\n",
    "#newcmap = cmocean.tools.crop_by_percent(cmo.matter, 15, which='max', N=None)\n",
    "\n",
    "# Loop for drawing each plot\n",
    "for k, ax in enumerate(axgr):\n",
    "    ax = draw_basemap(ax, extent=[lonmin,lonmax,latmin,latmax], xticks=dx, yticks=dy)\n",
    "#     ax = draw_basemap(ax, extent=None, xticks=dx, yticks=dy)\n",
    "    \n",
    "    # Add contour fill plot for IVT\n",
    "    udat = ds_cor.ivte.sel(pcs=k)\n",
    "    vdat = ds_cor.ivtn.sel(pcs=k)\n",
    "    data = np.sqrt(udat**2 + vdat**2)\n",
    "    clevs = np.arange(-1,1.1,0.1)\n",
    "    cf = ax.contourf(lons, lats, data, transform=datacrs,\n",
    "                     levels=clevs,\n",
    "                     cmap=\"bwr\", extend='both')\n",
    "#     # add vectors for extratropics\n",
    "#     ax.quiver(lons, lats, udat[k,:,:], vdat[k,:,:], transform=datacrs,\n",
    "#               color='black', pivot='middle', regrid_shape=30)\n",
    "\n",
    "    \n",
    "    # subtitles\n",
    "    ax.set_title(eof_label[k], loc='left', fontsize=12)\n",
    "#     ax.set_title(var_label[k], loc='right', fontsize=12)\n",
    "    \n",
    "# single colorbar\n",
    "cb = fig.colorbar(cf, axgr.cbar_axes[0], orientation='horizontal', drawedges=True)\n",
    "cb.set_label('correlation coefficient', fontsize=11)\n",
    "cb.ax.tick_params(labelsize=10)\n",
    "    \n",
    "# Display figure\n",
    "plt.savefig(filepath, dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ar_types)",
   "language": "python",
   "name": "ar_types"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "191.59375px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
