{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python modules\n",
    "import os, sys\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.ticker as mticker\n",
    "# plot styles/formatting\n",
    "import seaborn as sns\n",
    "import cmocean.cm as cmo\n",
    "import cmocean\n",
    "# cartopy\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "\n",
    "# Extra \n",
    "from scipy.ndimage import gaussian_filter    # smoothing contour lines\n",
    "from scipy import stats\n",
    "\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# import personal modules\n",
    "\n",
    "# Path to modules\n",
    "sys.path.append('../modules')\n",
    "\n",
    "# Import my modules\n",
    "from plotter import draw_basemap\n",
    "from timeseries import persistence, select_months, create_list_all_dates\n",
    "from teleconnections import build_teleconnection_df\n",
    "from statistical_tests import build_zscore_df, ttest_1samp_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "\n",
    "path_to_data = '/home/nash/DATA/data/'                            # project data -- read only\n",
    "path_to_out  = '/home/nash/DATA/repositories/AR_types/out/'       # output files (numerical results, intermediate datafiles) -- read & write\n",
    "path_to_figs = '/home/nash/DATA/repositories/AR_types/figs/'      # figures\n",
    "\n",
    "# USE pandas.options TO DISPLAY FLOATS TO TWO DECIMAL PLACES\n",
    "pd.options.display.float_format = \"{:,.2f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ceofid = 'HUV500'\n",
    "neofs = 2 # choose number of eofs\n",
    "nk = 3 # choose number of clusters\n",
    "ssn = 'djfmam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import configuration file for dictionary choice\n",
    "yaml_doc = '../data/config.yml'\n",
    "\n",
    "config = yaml.load(open(yaml_doc), Loader=yaml.SafeLoader)\n",
    "#select dictionaries - choose var, anom/nanom, and season\n",
    "# upper_ precip_ ivt_ and non_anom anom\n",
    "plot_dict_upper = config['upper_non_anom']\n",
    "plot_dict_ivt = config['ivt_non_anom']\n",
    "plot_dict_prec = config['precip_non_anom']\n",
    "\n",
    "plot_dicts = [plot_dict_upper, plot_dict_ivt, plot_dict_prec]\n",
    "\n",
    "# djf_dict mam_dict djfmam_dict\n",
    "ar_dict = config[ssn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ar_daily_df(ssn, nk):\n",
    "    out_path = path_to_out + ceofid + '/' + ssn + '/' + 'neof' + str(neofs) + '/k' + str(nk) + '/'\n",
    "    filepath = out_path + 'AR-types_ALLDAYS.csv'\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    # set up datetime index\n",
    "    df = df.rename(columns={'Unnamed: 0': 'date'})\n",
    "    df = df.set_index(pd.to_datetime(df.date))\n",
    "    \n",
    "    ## Break up columns into different AR Types\n",
    "    keys = []\n",
    "    for k in range(nk):\n",
    "        keys.append(\"AR_CAT{:1d}\".format(k+1,))\n",
    "\n",
    "    values = np.zeros((len(df.index)))\n",
    "    dicts = dict(zip(keys, values))\n",
    "\n",
    "    df_cat = pd.DataFrame(dicts, index=df.index)\n",
    "\n",
    "    for k in range(nk):\n",
    "        idx = (df['AR_CAT'] == k+1)\n",
    "        col = \"AR_CAT{:1d}\".format(k+1,)\n",
    "        df_cat.loc[idx, col] = 1\n",
    "        \n",
    "    # get total of all AR types\n",
    "    df_cat['AR_ALL'] = df_cat['AR_CAT1'] + df_cat['AR_CAT2'] + df_cat['AR_CAT3']\n",
    "    df_cat['AR_CAT'] = df['AR_CAT']\n",
    "    \n",
    "    return df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AO</th>\n",
       "      <th>PDO</th>\n",
       "      <th>ENSO</th>\n",
       "      <th>SH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979-03-01 09:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-03-02 09:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-03-03 09:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-03-04 09:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-03-05 09:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-27 09:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-28 09:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-29 09:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-30 09:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-31 09:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14337 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AO  PDO  ENSO  SH\n",
       "date                                  \n",
       "1979-03-01 09:00:00   0   -1     0  -1\n",
       "1979-03-02 09:00:00   1   -1     0  -1\n",
       "1979-03-03 09:00:00   1   -1     0  -1\n",
       "1979-03-04 09:00:00   1   -1     0  -1\n",
       "1979-03-05 09:00:00   1   -1     0  -1\n",
       "...                  ..  ...   ...  ..\n",
       "2018-05-27 09:00:00   1    0     0   1\n",
       "2018-05-28 09:00:00   1    0     0   1\n",
       "2018-05-29 09:00:00   0    0     0   1\n",
       "2018-05-30 09:00:00   0    0     0   1\n",
       "2018-05-31 09:00:00   0    0     0   1\n",
       "\n",
       "[14337 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = '1979-03-01'\n",
    "end_date = '2019-05-31'\n",
    "\n",
    "tele = build_teleconnection_df('daily', 'COND', start_date, end_date)\n",
    "tele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AR_CAT1</th>\n",
       "      <th>AR_CAT2</th>\n",
       "      <th>AR_CAT3</th>\n",
       "      <th>AR_ALL</th>\n",
       "      <th>AR_CAT</th>\n",
       "      <th>AO</th>\n",
       "      <th>PDO</th>\n",
       "      <th>ENSO</th>\n",
       "      <th>SH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979-12-01 09:00:00</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-12-02 09:00:00</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-12-03 09:00:00</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-12-04 09:00:00</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-12-05 09:00:00</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-27 09:00:00</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-28 09:00:00</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-29 09:00:00</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-30 09:00:00</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-31 09:00:00</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7290 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AR_CAT1  AR_CAT2  AR_CAT3  AR_ALL  AR_CAT   AO  PDO  \\\n",
       "date                                                                       \n",
       "1979-12-01 09:00:00     0.00     0.00     1.00    1.00       3 1.00 0.00   \n",
       "1979-12-02 09:00:00     0.00     0.00     1.00    1.00       3 1.00 0.00   \n",
       "1979-12-03 09:00:00     0.00     0.00     0.00    0.00       0 1.00 0.00   \n",
       "1979-12-04 09:00:00     0.00     0.00     0.00    0.00       0 1.00 0.00   \n",
       "1979-12-05 09:00:00     0.00     0.00     0.00    0.00       0 1.00 0.00   \n",
       "...                      ...      ...      ...     ...     ...  ...  ...   \n",
       "2019-05-27 09:00:00     0.00     0.00     0.00    0.00       0  nan  nan   \n",
       "2019-05-28 09:00:00     0.00     0.00     0.00    0.00       0  nan  nan   \n",
       "2019-05-29 09:00:00     0.00     0.00     0.00    0.00       0  nan  nan   \n",
       "2019-05-30 09:00:00     0.00     0.00     0.00    0.00       0  nan  nan   \n",
       "2019-05-31 09:00:00     0.00     0.00     0.00    0.00       0  nan  nan   \n",
       "\n",
       "                     ENSO   SH  \n",
       "date                            \n",
       "1979-12-01 09:00:00  0.00 0.00  \n",
       "1979-12-02 09:00:00  0.00 0.00  \n",
       "1979-12-03 09:00:00  0.00 0.00  \n",
       "1979-12-04 09:00:00  0.00 0.00  \n",
       "1979-12-05 09:00:00  0.00 0.00  \n",
       "...                   ...  ...  \n",
       "2019-05-27 09:00:00   nan  nan  \n",
       "2019-05-28 09:00:00   nan  nan  \n",
       "2019-05-29 09:00:00   nan  nan  \n",
       "2019-05-30 09:00:00   nan  nan  \n",
       "2019-05-31 09:00:00   nan  nan  \n",
       "\n",
       "[7290 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_index = select_months(tele, 12, 5)\n",
    "df = ar_daily_df(ssn, nk)\n",
    "# combine ar df with tele df\n",
    "# join indices with AR count\n",
    "new_df = df.join(df_index)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composite Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ds):\n",
    "    '''keep only selected lats and lons'''\n",
    "    if plot_dict['name'] == 'huv250':\n",
    "        subset = ds.sel(latitude=slice(latmax, latmin), longitude=slice(lonmin, lonmax), level=plot_dict['lev'])\n",
    "    else:\n",
    "        subset = ds.sel(latitude=slice(latmax, latmin), longitude=slice(lonmin, lonmax))\n",
    "    return subset\n",
    "\n",
    "f = []\n",
    "\n",
    "# Select lat/lon grid\n",
    "lonmin = 0.\n",
    "lonmax = 120\n",
    "latmin = 10\n",
    "latmax = 50\n",
    "\n",
    "    \n",
    "for p, plot_dict in enumerate(plot_dicts):\n",
    "\n",
    "    # # open data  \n",
    "    f.append(xr.open_mfdataset(path_to_data + plot_dict['fname'] , preprocess=preprocess, combine='by_coords'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds size in GB 5.85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var_dict = {'H': (['time', 'lat', 'lon'], (f[0]['z'].values/(9.80665))), # convert to geopotential height (m)\n",
    "            'U': (['time', 'lat', 'lon'], f[0]['u'].values),\n",
    "            'V': (['time', 'lat', 'lon'], f[0]['v'].values),\n",
    "            'ivte': (['time', 'lat', 'lon'], f[1]['p71.162'].values),\n",
    "            'ivtn': (['time', 'lat', 'lon'], f[1]['p72.162'].values)}\n",
    "\n",
    "\n",
    "ds1 = xr.Dataset(var_dict,\n",
    "                coords={'time': (['time'], f[0]['time'].values),\n",
    "                        'lat': (['lat'], f[0]['latitude'].values),\n",
    "                        'lon': (['lon'], f[0]['longitude'].values)})\n",
    "\n",
    "ds2 = xr.Dataset({'prec': (['time', 'lat', 'lon'], f[2]['mtpr'].values*86400)},\n",
    "                coords={'time': (['time'], f[2]['time'].values),\n",
    "                        'lat': (['lat'], f[2]['latitude'].values),\n",
    "                        'lon': (['lon'], f[2]['longitude'].values)})\n",
    "ds1\n",
    "print('ds size in GB {:0.2f}\\n'.format(ds1.nbytes / 1e9))\n",
    "\n",
    "ds_lst = [ds1, ds2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e986f7c8dbc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mds_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "df = new_df\n",
    "for i, ds in enumerate(ds_lst):\n",
    "    # Trim date range\n",
    "    idx = slice(ar_dict['start_date'], ar_dict['end_date'])\n",
    "    ds = ds.sel(time=idx)\n",
    "    \n",
    "    # Select months\n",
    "    if ar_dict['mon_s'] > ar_dict['mon_e']:\n",
    "        idx = (ds.time.dt.month >= ar_dict['mon_s']) | (ds.time.dt.month <= ar_dict['mon_e'])\n",
    "    else:\n",
    "        idx = (ds.time.dt.month >= ar_dict['mon_s']) & (ds.time.dt.month <= ar_dict['mon_e'])\n",
    "    ds = ds.sel(time=idx)\n",
    "    \n",
    "    # Combine AR Cat data w/ reanalysis data\n",
    "    # Add ar time series to the ERA dataset\n",
    "    cols = ['AR_CAT', 'AO', 'ENSO', 'SH']\n",
    "    for i, col in enumerate(cols):\n",
    "        ds[col] = ('time', df[col])\n",
    "\n",
    "    ds = ds.set_coords(tuple(cols))\n",
    "    \n",
    "    ds_lst[i] = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['AO', 'ENSO', 'SH']\n",
    "popmean=np.zeros([len(ds.lat), len(ds.lon)])\n",
    "data_lst = []\n",
    "tval_lst = []\n",
    "\n",
    "for i, tele in enumerate(cols):\n",
    "    # all days positive teleconnection\n",
    "    idx = (ds[tele] == 1)\n",
    "    tmp = ds.sel(time=idx)\n",
    "    # make time series of [0, 1, 0, 0] for dates where conditions are met\n",
    "    date_lst = tmp.time.values\n",
    "    df_tmp = create_list_all_dates(start_date, end_date, date_lst)\n",
    "    # calculate number of independent events\n",
    "    event_id, nevents, duration = persistence(df_tmp)\n",
    "    \n",
    "    # calculate t-value based on nevents\n",
    "    a_mean, tval_mask = ttest_1samp_new(a=tmp, popmean=popmean, dim='time', n=nevents)\n",
    "    data_lst.append(a_mean)\n",
    "#     tval_lst.append(np.ones(tval_mask.shape, dtype=bool)) # make a tval mask with all True\n",
    "    tval_lst.append(tval_mask)\n",
    "    idx_lst = [(tmp['AR_CAT'] > 0),  (tmp['AR_CAT'] == 1),  (tmp['AR_CAT'] == 2),  (tmp['AR_CAT'] == 3)]\n",
    "    \n",
    "    # repeat for each AR Type Grouping\n",
    "    for j, idx in enumerate(idx_lst):\n",
    "        tmp_ar = tmp.sel(time=idx_lst[j])\n",
    "        \n",
    "        # make time series of [0, 1, 0, 0] for dates where conditions are met\n",
    "        date_lst = tmp_ar.time.values\n",
    "        df_tmp = create_list_all_dates(start_date, end_date, date_lst)\n",
    "\n",
    "        # calculate number of independent events\n",
    "        event_id, nevents, duration = persistence(df_tmp)\n",
    "\n",
    "        # calculate t-value based on nevents\n",
    "        a_mean, tval_mask = ttest_1samp_new(a=tmp_ar, popmean=popmean, dim='time', n=nevents)\n",
    "        data_lst.append(a_mean)\n",
    "        tval_lst.append(tval_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seaborn plot style\n",
    "sns.set()\n",
    "sns.set_style(\"ticks\", {'patch.force_edgecolor':False})\n",
    "\n",
    "# Set up projection\n",
    "mapcrs = ccrs.NorthPolarStereo()\n",
    "datacrs = ccrs.PlateCarree()\n",
    "\n",
    "# Set tick/grid locations\n",
    "dx = np.arange(lonmin,lonmax+20,20)\n",
    "dy = np.arange(latmin,latmax+20,20)\n",
    "\n",
    "# # cmap with white in the middle\n",
    "# n=50\n",
    "# x = 0.25\n",
    "# lower = plt.cm.seismic(np.linspace(0, x, n))\n",
    "# white = plt.cm.seismic(np.ones(100)*0.25)\n",
    "# upper = plt.cm.seismic(np.linspace(1-x, 1, n))\n",
    "# colors = np.vstack((lower, white, upper))\n",
    "# tmap = mpl.colors.LinearSegmentedColormap.from_list('terrain_map_white', colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = path_to_figs + ceofid + '/' + ssn + '/'+ 'neof' + str(neofs) + '/k' + str(nk) + '/'\n",
    "filepath = fig_path + 'composite_teleconnection_H.png'    \n",
    "nrows = 5\n",
    "ncols = 4\n",
    "\n",
    "cols = ['AO', 'PDO', 'ENSO', 'SH']\n",
    "plt_lbls = ['AO']+['']*4 + ['PDO']+['']*4 +['ENSO']+['']*4 + ['SH']+['']*4\n",
    "row_lbl1 = ['All Days','AR Days','AR Type 1','AR Type 2', 'AR Type 3']+ ['']*15\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(10,15))\n",
    "\n",
    "# Set up Axes Grid\n",
    "axes_class = (GeoAxes,dict(map_projection=mapcrs))\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "                nrows_ncols=(nrows, ncols), axes_pad = 0.2,\n",
    "                cbar_location='bottom', cbar_mode='single',\n",
    "                cbar_pad=0.10, cbar_size='2%',label_mode='',\n",
    "                direction='column')\n",
    "\n",
    "for k, ax in enumerate(axgr): \n",
    "    # data for plotting\n",
    "    data = data_lst[k]\n",
    "    tval = tval_lst[k]\n",
    "    \n",
    "    # lat/lon arrays\n",
    "    lats = data.lat.values\n",
    "    lons = data.lon.values \n",
    "    ax = draw_basemap(ax, extent=[lonmin,lonmax,latmin,latmax], grid=True)\n",
    "    \n",
    "    # Contour Filled (mask==True) (only significant values)\n",
    "    hgts_mask = data.H.where(tval.H == True).values #convert to decimeters\n",
    "#     hgts = data\n",
    "    cflevs = np.arange(-90, 95, 15)\n",
    "    cf = ax.contourf(lons, lats, hgts_mask, transform=datacrs,\n",
    "                     levels=cflevs, cmap='RdBu_r', alpha=0.9, extend='both')\n",
    "    \n",
    "#     # Contour (ALL)\n",
    "#     hgts_mask = data.where(tval_mask == False)\n",
    "#     cf_mask = ax.contourf(lons, lats, hgts_mask, transform=datacrs,\n",
    "#                      levels=cflevs, cmap=cmap, alpha=0.25, extend='both')\n",
    "\n",
    "    hgts = data.H.values\n",
    "    clevs = np.arange(-60, 65, 15)\n",
    "    cs = ax.contour(lons, lats, hgts, transform=datacrs,\n",
    "                    levels=clevs, colors='k', linewidths=0.75)\n",
    "#     plt.clabel(cs, fmt='%d',fontsize=8.5, inline_spacing=5) \n",
    "    \n",
    "    # plot titles\n",
    "    ax.set_title(plt_lbls[k], fontsize=13)\n",
    "    # Row labels\n",
    "    ax.text(-0.07, 0.55, row_lbl1[k], va='bottom', ha='center',\n",
    "        rotation='vertical', rotation_mode='anchor', fontsize=13,\n",
    "        transform=ax.transAxes)\n",
    "                  \n",
    "# # Colorbar (single)\n",
    "cb = fig.colorbar(cf, axgr.cbar_axes[0], orientation='horizontal', drawedges=True, spacing='uniform')\n",
    "cb.set_label('m')\n",
    "    \n",
    "# Save figure\n",
    "plt.savefig(filepath, dpi=150, bbox_inches='tight')\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = path_to_figs + ceofid + '/' + ssn + '/'+ 'neof' + str(neofs) + '/k' + str(nk) + '/'\n",
    "filepath = fig_path + 'composite_teleconnection_UV.png'    \n",
    "nrows = 5\n",
    "ncols = 4\n",
    "\n",
    "cols = ['AO', 'PDO', 'ENSO', 'SH']\n",
    "plt_lbls = ['AO']+['']*4 + ['PDO']+['']*4 +['ENSO']+['']*4 + ['SH']+['']*4\n",
    "row_lbl1 = ['All Days','AR Days','AR Type 1','AR Type 2', 'AR Type 3']+ ['']*15\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(10,15))\n",
    "\n",
    "# Set up Axes Grid\n",
    "axes_class = (GeoAxes,dict(map_projection=mapcrs))\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "                nrows_ncols=(nrows, ncols), axes_pad = 0.2,\n",
    "                cbar_location='bottom', cbar_mode='single',\n",
    "                cbar_pad=0.10, cbar_size='2%',label_mode='',\n",
    "                direction='column')\n",
    "\n",
    "for k, ax in enumerate(axgr): \n",
    "    # data for plotting\n",
    "    data = data_lst[k]\n",
    "    tval = tval_lst[k]\n",
    "    \n",
    "    # lat/lon arrays\n",
    "    lats = data.lat.values\n",
    "    lons = data.lon.values \n",
    "    ax = draw_basemap(ax, extent=[lonmin,lonmax,latmin,latmax], grid=True)\n",
    "    \n",
    "    # Contour Filled (mask==True) (only significant values)\n",
    "    uwnd = data.U.values\n",
    "    vwnd = data.V.values\n",
    "    wnd_mag = np.sqrt(uwnd**2+vwnd**2)\n",
    "    cflevs = np.arange(0, 14, 2)\n",
    "    cf = ax.contourf(lons, lats, wnd_mag, transform=datacrs,\n",
    "                     levels=cflevs, cmap='BuPu', alpha=0.9, extend='neither')\n",
    "    \n",
    "    # Wind barbs / vectors (only plot where significant)\n",
    "    # accept u and v if either is significant\n",
    "    uwnd_mask = data.U.where((tval.U == True) | (tval.V == True)).values\n",
    "    vwnd_mask = data.V.where((tval.U == True) | (tval.V == True)).values\n",
    "    Q = ax.quiver(lons, lats, uwnd_mask, vwnd_mask, transform=datacrs, \n",
    "                  color='k', regrid_shape=25\n",
    "#                   ,pivot='middle',\n",
    "#                   angles='xy', scale_units='xy', scale=2, units='xy'\n",
    "                 )\n",
    "    \n",
    "    # quiver key\n",
    "    qk = ax.quiverkey(Q, 0.7, 1.07, 2, '2 m s$^{-1}$', labelpos='E',\n",
    "                     coordinates='axes', fontproperties={'size': 8.0})\n",
    "    \n",
    "    # plot titles\n",
    "    ax.set_title(plt_lbls[k], fontsize=13)\n",
    "    # Row labels\n",
    "    ax.text(-0.07, 0.55, row_lbl1[k], va='bottom', ha='center',\n",
    "        rotation='vertical', rotation_mode='anchor', fontsize=13,\n",
    "        transform=ax.transAxes)\n",
    "                  \n",
    "# # Colorbar (single)\n",
    "cb = fig.colorbar(cf, axgr.cbar_axes[0], orientation='horizontal', drawedges=True, spacing='uniform')\n",
    "cb.set_label('m')\n",
    "    \n",
    "# Save figure\n",
    "plt.savefig(filepath, dpi=150, bbox_inches='tight')\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ar_types",
   "language": "python",
   "name": "ar_types"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
