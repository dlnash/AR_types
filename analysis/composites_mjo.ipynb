{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AR composites (both anomaly/non-anomaly) of different variables using different cEOF tests (e.g. DJF, MAM, DJF-MAM). \n",
    "\n",
    "1. (upper) 250-hPa geopotential heights (contour lines), isotachs (contour shading), and wind vectors\n",
    "2. (precip) \n",
    "3. (ivt)\n",
    "4. (slp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python modules\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.colors import ListedColormap\n",
    "# plot styles/formatting\n",
    "import seaborn as sns\n",
    "import cmocean.cm as cmo\n",
    "import cmocean\n",
    "# cartopy\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "\n",
    "# Extra \n",
    "from scipy.ndimage import gaussian_filter    # smoothing contour lines\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# import personal modules\n",
    "\n",
    "# Path to modules\n",
    "sys.path.append('../modules')\n",
    "\n",
    "# Import my modules\n",
    "from plotter import draw_basemap\n",
    "from timeseries import ttest_1samp_lag, persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "\n",
    "path_to_data = '/home/nash/DATA/data/'                            # project data -- read only\n",
    "path_to_out  = '/home/nash/DATA/repositories/AR_types/out/'       # output files (numerical results, intermediate datafiles) -- read & write\n",
    "path_to_figs = '/home/nash/DATA/repositories/AR_types/figs/composites/'      # figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a default font for all matplotlib text \n",
    "rcParams['font.family'] = 'sans-serif'   # font family = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = 'Arial'    # default sans-serif font = 'Arial'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Upper level plots\n",
    "upper_non_anom = {'name': 'huv250',\n",
    "                  'anom': 'nanom',\n",
    "                  'fname': 'ERA5/huvq/daily/out.era5_hma_05dg_daily_huvq_*.nc',\n",
    "                  'bnds': [30., 120., 0., 65.],\n",
    "                  'lev': 250.,\n",
    "                  'cflevs': np.arange(40,131,10),\n",
    "                  'cmap': 'BuPu',\n",
    "                  'clevs': np.arange(840,1280,12),\n",
    "                  'quiver_scale': 10,\n",
    "                  'quiver_key': 25,\n",
    "                  'quiver_key_lbl': r'25 m s$^{-1}$',\n",
    "                  'cb_label': 'wind speed (kt)',\n",
    "                  'fig_name_prefix': 'ar_types_upper_'}\n",
    "\n",
    "upper_anom = {'name': 'huv250',\n",
    "              'anom': 'anom',\n",
    "              'fname': 'ERA5/huvq/anomalies/daily_filtered_anomalies_huvq_*.nc',\n",
    "              'bnds': [30., 120., 0., 65.],\n",
    "              'cflevs': np.arange(0,43,6),\n",
    "              'cmap': 'BuPu',\n",
    "              'clevs': np.arange(-10,11,2),\n",
    "              'quiver_scale': 2,\n",
    "              'quiver_key': 10,\n",
    "              'quiver_key_lbl': r'10 m s$^{-1}$',\n",
    "              'cb_label': 'wind speed (kt)',\n",
    "              'fig_name_prefix': 'anom_ar_types_upper_'}\n",
    "\n",
    "# 2) Precip Plots\n",
    "precip_non_anom = {'name': 'prec',\n",
    "                   'anom': 'nanom',\n",
    "                   'fname': 'ERA5/prec/daily/out.era5_hma_025dg_daily_prec_*.nc',\n",
    "                   'bnds': [40., 120., 10., 50.],\n",
    "                   'cflevs': np.arange(2,22,2),\n",
    "                   'cmap': cmo.rain,\n",
    "                   'clevs': None,\n",
    "                   'quiver_scale': None,\n",
    "                   'quiver_key': None,\n",
    "                   'quiver_key_lbl': None,\n",
    "                   'cb_label': 'mm day-1',\n",
    "                   'fig_name_prefix': 'ar_types_prec_'}\n",
    "\n",
    "precip_anom = {'name': 'prec',\n",
    "               'anom': 'anom',\n",
    "               'fname': 'ERA5/prec/anomalies/daily_filtered_anomalies_*.nc',\n",
    "               'bnds': [40., 120., 10., 50.],\n",
    "               'cflevs': np.arange(-6,22,2),\n",
    "               'cmap': cmocean.tools.crop(cmo.balance, vmin=-6., vmax=22., pivot=0., N=None, dmax=None),\n",
    "               'clevs': None,\n",
    "               'quiver_scale': None,\n",
    "               'quiver_key': None,\n",
    "               'quiver_key_lbl': None,\n",
    "               'cb_label': 'mm day-1',\n",
    "               'fig_name_prefix': 'anom_ar_types_prec_'}\n",
    "\n",
    "# 3) IVT plots\n",
    "ivt_non_anom = {'name': 'ivt',\n",
    "                'anom': 'nanom',\n",
    "                'fname': 'ERA5/ivt/daily/out.era5*.nc',\n",
    "                'bnds': [30., 120., 0., 50.],\n",
    "                'cflevs': np.arange(100,601,50),\n",
    "                'cmap': cmo.deep,\n",
    "                'clevs': None,\n",
    "                'quiver_scale': 50,\n",
    "                'quiver_key': 250,\n",
    "                'quiver_key_lbl': r'250 kg m$^{-1}$ s$^{-1}$',\n",
    "                'cb_label': 'kg m$^{-1}$ s$^{-1}$',\n",
    "                'fig_name_prefix': 'ar_types_ivt_'}\n",
    "\n",
    "ivt_anom = {'name': 'ivt',\n",
    "            'anom': 'anom',\n",
    "            'fname': 'ERA5/ivt/anomalies/daily_filtered_anomalies_*.nc',\n",
    "            'bnds': [30., 120., 0., 50.],\n",
    "            'cflevs': np.arange(10,180,10),\n",
    "            'cmap': cmo.deep,\n",
    "            'clevs': None,\n",
    "            'quiver_scale': 10,\n",
    "            'quiver_key': 25,\n",
    "            'quiver_key_lbl': r'25 kg m$^{-1}$ s$^{-1}$',\n",
    "            'cb_label': 'kg m$^{-1}$ s$^{-1}$',\n",
    "            'fig_name_prefix': 'anom_ar_types_ivt_'}\n",
    "\n",
    "## Possible choices for cEOF k-means - a) DJF b) MAM c) DJF-MAM\n",
    "djf_dict = {'start_date': '1979-12-01',\n",
    "             'end_date': '2018-02-28',\n",
    "             'mon_s': 12,\n",
    "             'mon_e': 2,\n",
    "             'ys': 1979,\n",
    "             'ye': 2018,\n",
    "             'day_s': '01',\n",
    "             'day_e': '28',\n",
    "             'ssn': 'djf'}\n",
    "\n",
    "# Option 2 - MAM only\n",
    "mam_dict = {'start_date': '1979-03-01',\n",
    "             'end_date': '2018-5-31',\n",
    "             'mon_s': 3,\n",
    "             'mon_e': 5,\n",
    "             'ys': 1979,\n",
    "             'ye': 2018,\n",
    "             'day_s': '01',\n",
    "             'day_e': '31',\n",
    "             'ssn': 'mam'}\n",
    "\n",
    "# Option 3 - DJF and MAM combined\n",
    "djfmam_dict = {'start_date': '1979-03-01',\n",
    "               'end_date': '2018-5-31',\n",
    "               'mon_s': 12,\n",
    "               'mon_e': 5,\n",
    "               'ys': 1979,\n",
    "               'ye': 2018,\n",
    "               'day_s': '01',\n",
    "               'day_e': '31',\n",
    "               'ssn': 'djfmam'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select dictionaries - choose var, anom/nanom, and season\n",
    "# upper_ precip_ ivt_ and non_anom anom\n",
    "plot_dict = upper_anom\n",
    "# djf_dict mam_dict djfmam_dict\n",
    "ar_dict = mam_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ERA5 renalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lev'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f9326524ad60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# # open data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mfilepath_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_data\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mplot_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fname'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_mfdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'by_coords'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/sbarc/students/nash/anaconda3/envs/ar_types/lib/python3.7/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_mfdataset\u001b[0;34m(paths, chunks, concat_dim, compat, preprocess, engine, lock, data_vars, coords, combine, autoclose, parallel, join, attrs_file, **kwargs)\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0mfile_objs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_file_obj\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreprocess\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m         \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sbarc/students/nash/anaconda3/envs/ar_types/lib/python3.7/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0mfile_objs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_file_obj\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreprocess\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m         \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f9326524ad60>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(ds)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m'''keep only selected lats and lons'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mplot_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'huv250'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlongitude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlonmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlonmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplot_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lev'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlongitude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlonmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlonmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lev'"
     ]
    }
   ],
   "source": [
    "# Select lat/lon grid\n",
    "lonmin = plot_dict['bnds'][0]\n",
    "lonmax = plot_dict['bnds'][1]\n",
    "latmin = plot_dict['bnds'][2]\n",
    "latmax = plot_dict['bnds'][3]\n",
    "\n",
    "def preprocess(ds):\n",
    "    '''keep only selected lats and lons'''\n",
    "    if plot_dict['name'] == 'huv250':\n",
    "        subset = ds.sel(latitude=slice(latmax, latmin), longitude=slice(lonmin, lonmax), level=plot_dict['lev'])\n",
    "    else:\n",
    "        subset = ds.sel(latitude=slice(latmax, latmin), longitude=slice(lonmin, lonmax))\n",
    "    return subset\n",
    "\n",
    "# # open data\n",
    "filepath_pattern = path_to_data + plot_dict['fname']   \n",
    "f1 = xr.open_mfdataset(filepath_pattern, preprocess=preprocess, combine='by_coords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if plot_dict['name'] == 'huv250':\n",
    "    var_dict = {'H': (['time', 'lat', 'lon'], f1['z'].values/(9.80665*10)), # convert to geopotential height (m)\n",
    "                'U': (['time', 'lat', 'lon'], f1['u'].values),\n",
    "                'V': (['time', 'lat', 'lon'], f1['v'].values)}\n",
    "elif plot_dict['name'] == 'prec':\n",
    "    var_dict = {'prec': (['time', 'lat', 'lon'], f1['mtpr'].values*86400)}\n",
    "elif plot_dict['name'] == 'ivt':\n",
    "    var_dict = {'ivte': (['time', 'lat', 'lon'], f1['p71.162'].values),\n",
    "                'ivtn': (['time', 'lat', 'lon'], f1['p72.162'].values)}\n",
    "\n",
    "ds = xr.Dataset(var_dict,\n",
    "                coords={'time': (['time'], f1.time.values),\n",
    "                        'lat': (['lat'], f1.latitude.values),\n",
    "                        'lon': (['lon'], f1.longitude.values)})\n",
    "ds\n",
    "print('ds size in GB {:0.2f}\\n'.format(ds.nbytes / 1e9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AR days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_id = 'HUV500t0120050cor'\n",
    "filepath = path_to_out + fname_id + 'hma_AR-types-' + ar_dict['ssn'] + '.csv'\n",
    "df = pd.read_csv(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim date range\n",
    "idx = slice(ar_dict['start_date'], ar_dict['end_date'])\n",
    "ds = ds.sel(time=idx)\n",
    "\n",
    "# Select DJF months\n",
    "# Select months\n",
    "if ar_dict['mon_s'] > ar_dict['mon_e']:\n",
    "    idx = (ds.time.dt.month >= ar_dict['mon_s']) | (ds.time.dt.month <= ar_dict['mon_e'])\n",
    "else:\n",
    "    idx = (ds.time.dt.month >= ar_dict['mon_s']) & (ds.time.dt.month <= ar_dict['mon_e'])\n",
    "    \n",
    "ds = ds.sel(time=idx)\n",
    "\n",
    "# Combine AR Cat data w/ reanalysis data\n",
    "# Add ar time series to the ERA dataset\n",
    "ds['ar'] = ('time', df.AR_CAT)\n",
    "ds = ds.set_coords('ar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_ar_days(era, lag=0):\n",
    "    # Select only AR days\n",
    "    idx = (era.ar >= 1)\n",
    "    # select days with lag shift\n",
    "    era_ar = era.shift(time=lag).sel(time=idx)\n",
    "    # print results\n",
    "    print(era_ar)\n",
    "    \n",
    "    return era_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag=0, -2, +2\n",
    "era_ar_lag0 = select_ar_days(era=ds, lag=0)\n",
    "era_ar_lag2 = select_ar_days(era=ds, lag=-2)\n",
    "era_ar_lead2 = select_ar_days(era=ds, lag=2)\n",
    "\n",
    "# combine lag datasets into 1 ds object\n",
    "era_ar_lag = xr.concat([era_ar_lead2, era_ar_lag0, era_ar_lag2], pd.Index([-2, 0, 2], name='lag'))\n",
    "era_ar_lag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute AR Composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of independent AR events\n",
    "\n",
    "years = np.arange(ar_dict['ys'], ar_dict['ye']) \n",
    "nyrs = len(years)\n",
    "total_events = 0\n",
    "for k in range(nyrs-1):    \n",
    "    # Extract single season\n",
    "    date1 = \"{0}-{1}-{2}\".format(years[k], ar_dict['mon_s'], ar_dict['day_s'])\n",
    "    date2 = \"{0}-{1}-{2}\".format(years[k+1], ar_dict['mon_e'], ar_dict['day_e'])\n",
    "    x = ds.ar.sel(time=slice(date1,date2)).values\n",
    "    # Count AR events in that season\n",
    "    tags, tmp = persistence(x)\n",
    "    # Add to running event count\n",
    "    total_events += tmp\n",
    "\n",
    "print(\"Number of independent AR events: \", total_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute composites of each AR type\n",
    "era_ar_comp = era_ar_lag.groupby('ar').mean('time')\n",
    "\n",
    "# run 1-sample t-test, mask results below 95% confidence level\n",
    "if plot_dict['anom'] == 'anom':\n",
    "    tval_mask, pval_mask = independent_ttest(ds=era_ar_lag, group='ar', alpha=0.05, df=total_events-2)\n",
    "    era_ar_comp = era_ar_comp.where(tval_mask == True)\n",
    "else:\n",
    "    era_ar_comp = era_ar_comp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figures:\n",
    "\n",
    "1. 0-Lag Composites (main, 3-panel)\n",
    "2. 0-lag Composites w/ lags (supplementary, 9-panel)\n",
    "3. Lag only composites (supplementary, 6-panel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-panel plot\n",
    "panel_3 =  {'nrows': 3,\n",
    "             'ncols': 1,\n",
    "             'lag_lst': [0, 0, 0],\n",
    "             'artype_lst': [1, 2, 3],\n",
    "             'panel': '3pan'}\n",
    "\n",
    "# 6-panel plot\n",
    "panel_6 = {'nrows': 3,\n",
    "            'ncols': 2,\n",
    "            'lag_lst': [-2, -2, -2, 2, 2, 2],\n",
    "            'artype_lst': [1, 2, 3, 1, 2, 3],\n",
    "            'panel': '6pan'}\n",
    "# 9-panel plot    \n",
    "panel_9 = {'nrows': 3,\n",
    "            'ncols': 3,\n",
    "            'lag_lst': [-2, -2, -2, 0, 0, 0, 2, 2, 2],\n",
    "            'artype_lst': [1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
    "            'panel': '9pan'}\n",
    "\n",
    "panel_dict = [panel_3, panel_6, panel_9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Plot Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seaborn plot style\n",
    "sns.set()\n",
    "sns.set_style(\"ticks\", {'patch.force_edgecolor':False})\n",
    "\n",
    "# Set projections\n",
    "datacrs = ccrs.PlateCarree()   # data/source\n",
    "mapcrs = ccrs.PlateCarree()    # map/destination\n",
    "\n",
    "# Set tick/grid locations\n",
    "dx = np.arange(lonmin,lonmax+20,20)\n",
    "dy = np.arange(latmin,latmax+20,20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upper Level Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through to create 3-panel, 6-panel, and 9-panel plot\n",
    "for m in range(len(panel_dict)):\n",
    "    fig_dict = panel_dict[m]\n",
    "    \n",
    "    filepath = path_to_figs + plot_dict['anom'] + '/' + 'HUV500_' + plot_dict['name']  + '_' + ar_dict['ssn'] + fig_dict['panel'] + '.png'\n",
    "    nrows = fig_dict['nrows']\n",
    "    ncols = fig_dict['ncols']\n",
    "    lag_lst = fig_dict['lag_lst']\n",
    "    artype_lst = fig_dict['artype_lst']\n",
    "\n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "    # Set up Axes Grid\n",
    "    axes_class = (GeoAxes,dict(map_projection=mapcrs))\n",
    "    axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "                    nrows_ncols=(nrows, ncols), axes_pad = 0.55,\n",
    "                    cbar_location='bottom', cbar_mode='single',\n",
    "                    cbar_pad=0.02, cbar_size='3%',label_mode='',\n",
    "                    direction='column')\n",
    "\n",
    "    # loop to draw plots\n",
    "    for k, (ax, lag, ar_type) in enumerate(zip(axgr, lag_lst, artype_lst)):\n",
    "        data = era_ar_comp.sel(lag=lag, ar=ar_type)\n",
    "        # lat/lon arrays\n",
    "        lats = data.lat.values\n",
    "        lons = data.lon.values    \n",
    "        ax = draw_basemap(ax, extent=[lonmin,lonmax,latmin,latmax], xticks=dx, yticks=dy)\n",
    "    \n",
    "        # Contour Filled\n",
    "\n",
    "        # 250-hPa Winds (m/s)\n",
    "        uwnd = data.U.values * units('m/s')\n",
    "        vwnd = data.V.values * units('m/s')\n",
    "        wspd = mpcalc.wind_speed(uwnd, vwnd)\n",
    "        # 250-hPa Winds (knots)\n",
    "        uwnd_kt = wspd.to('kt')\n",
    "        vwnd_kt = wspd.to('kt')\n",
    "        wspd_kt = wspd.to('kt')\n",
    "        cf = ax.contourf(lons, lats, wspd_kt, transform=datacrs,\n",
    "                         levels=plot_dict['cflevs'], cmap=plot_dict['cmap'], alpha=0.9, extend='max')\n",
    "    \n",
    "        # Contour Lines\n",
    "\n",
    "        # 250-hPa Heights\n",
    "        hgts = data.H.values\n",
    "        cs = ax.contour(lons, lats, hgts, transform=datacrs,\n",
    "                        levels=plot_dict['clevs'], colors='k', linewidths=1.1)\n",
    "        plt.clabel(cs, fmt='%d',fontsize=8.5, inline_spacing=5)  \n",
    "        \n",
    "        # Wind barbs / vectors\n",
    "        Q = ax.quiver(lons, lats, uwnd, vwnd, transform=datacrs, \n",
    "                      color='k', regrid_shape=20, pivot='middle',\n",
    "                      angles='xy', scale_units='xy', scale=plot_dict['quiver_scale'], units='xy')\n",
    "    \n",
    "        # quiver key\n",
    "        qk = ax.quiverkey(Q, 0.7, 1.07, plot_dict['quiver_key'], plot_dict['quiver_key_lbl'], labelpos='E',\n",
    "                          coordinates='axes', fontproperties={'size': 8.0})\n",
    "       # subtitles\n",
    "        plt_label = 'AR Type {0} Lag {1}'.format(ar_type, lag)\n",
    "        ax.set_title(plt_label, loc='left',fontsize=13)\n",
    "    \n",
    "    \n",
    "    # Colorbar (single)\n",
    "    cb = fig.colorbar(cf, axgr.cbar_axes[0], orientation='horizontal', drawedges=True, extend='both')\n",
    "    cb.set_label(plot_dict['cb_label'])\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(filepath, dpi=150, bbox_inches='tight')\n",
    "\n",
    "    # Show\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IVT Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through to create 3-panel, 6-panel, and 9-panel plot\n",
    "for m in range(len(panel_dict)):\n",
    "    fig_dict = panel_dict[m]\n",
    "    \n",
    "    filepath = path_to_figs + plot_dict['anom'] + '/' + 'HUV500_' + plot_dict['name']  + '_' + ar_dict['ssn'] + fig_dict['panel'] + '.png'    nrows = fig_dict['nrows']\n",
    "    ncols = fig_dict['ncols']\n",
    "    lag_lst = fig_dict['lag_lst']\n",
    "    artype_lst = fig_dict['artype_lst']\n",
    "\n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "    # Set up Axes Grid\n",
    "    axes_class = (GeoAxes,dict(map_projection=mapcrs))\n",
    "    axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "                    nrows_ncols=(nrows, ncols), axes_pad = 0.55,\n",
    "                    cbar_location='bottom', cbar_mode='single',\n",
    "                    cbar_pad=0.02, cbar_size='3%',label_mode='',\n",
    "                    direction='column')\n",
    "\n",
    "    # loop to draw plots\n",
    "    for k, (ax, lag, ar_type) in enumerate(zip(axgr, lag_lst, artype_lst)):\n",
    "        data = era_ar_comp.sel(lag=lag, ar=ar_type)\n",
    "        # lat/lon arrays\n",
    "        lats = data.lat.values\n",
    "        lons = data.lon.values    \n",
    "        ax = draw_basemap(ax, extent=[lonmin,lonmax,latmin,latmax], xticks=dx, yticks=dy)\n",
    "    \n",
    "        # Contour Filled\n",
    "        \n",
    "        # IVT (filled contour)\n",
    "        uvec = data.ivte.values\n",
    "        vvec = data.ivtn.values\n",
    "        ivt = np.sqrt(uvec**2 + vvec**2)\n",
    "        cf = ax.contourf(lons, lats, ivt, transform=datacrs,\n",
    "                         levels=plot_dict['cflevs'], cmap=plot_dict['cmap'], alpha=0.9, extend='max') \n",
    "        \n",
    "        # Wind barbs / vectors\n",
    "        Q = ax.quiver(lons, lats, uvec, vvec, transform=datacrs, \n",
    "                      color='k', regrid_shape=20, pivot='middle',\n",
    "                      angles='xy', scale_units='xy', scale=plot_dict['quiver_scale'], units='xy')\n",
    "    \n",
    "        # quiver key\n",
    "        qk = ax.quiverkey(Q, 0.7, 1.07, plot_dict['quiver_key'], plot_dict['quiver_key_lbl'], labelpos='E',\n",
    "                          coordinates='axes', fontproperties={'size': 8.0})\n",
    "       # subtitles\n",
    "        plt_label = 'AR Type {0} Lag {1}'.format(ar_type, lag)\n",
    "        ax.set_title(plt_label, loc='left',fontsize=13)\n",
    "    \n",
    "    \n",
    "    # Colorbar (single)\n",
    "    cb = fig.colorbar(cf, axgr.cbar_axes[0], orientation='horizontal', drawedges=True, extend='both')\n",
    "    cb.set_label(plot_dict['cb_label'])\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(filepath, dpi=150, bbox_inches='tight')\n",
    "\n",
    "    # Show\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precip Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through to create 3-panel, 6-panel, and 9-panel plot\n",
    "for m in range(len(panel_dict)):\n",
    "    fig_dict = panel_dict[m]\n",
    "    \n",
    "    filepath = path_to_figs + plot_dict['anom'] + '/' + 'HUV500_' + plot_dict['name']  + '_' + ar_dict['ssn'] + fig_dict['panel'] + '.png'    nrows = fig_dict['nrows']\n",
    "    ncols = fig_dict['ncols']\n",
    "    lag_lst = fig_dict['lag_lst']\n",
    "    artype_lst = fig_dict['artype_lst']\n",
    "\n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "    # Set up Axes Grid\n",
    "    axes_class = (GeoAxes,dict(map_projection=mapcrs))\n",
    "    axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "                    nrows_ncols=(nrows, ncols), axes_pad = 0.55,\n",
    "                    cbar_location='bottom', cbar_mode='single',\n",
    "                    cbar_pad=0.02, cbar_size='3%',label_mode='',\n",
    "                    direction='column')\n",
    "\n",
    "    # loop to draw plots\n",
    "    for k, (ax, lag, ar_type) in enumerate(zip(axgr, lag_lst, artype_lst)):\n",
    "        data = era_ar_comp.sel(lag=lag, ar=ar_type)\n",
    "        # lat/lon arrays\n",
    "        lats = data.lat.values\n",
    "        lons = data.lon.values    \n",
    "        ax = draw_basemap(ax, extent=[lonmin,lonmax,latmin,latmax], xticks=dx, yticks=dy)\n",
    "    \n",
    "        # Contour Filled\n",
    "\n",
    "        # Precip (filled contour)\n",
    "        prec = data.prec.values\n",
    "        cf = ax.contourf(lons, lats, prec, transform=datacrs,\n",
    "                         levels=plot_dict['cflevs'], cmap=plot_dict['cmap'], alpha=0.9, extend='max')\n",
    "    \n",
    "       # subtitles\n",
    "        plt_label = 'AR Type {0} Lag {1}'.format(ar_type, lag)\n",
    "        ax.set_title(plt_label, loc='left',fontsize=13)\n",
    "    \n",
    "    \n",
    "    # Colorbar (single)\n",
    "    cb = fig.colorbar(cf, axgr.cbar_axes[0], orientation='horizontal', drawedges=True, extend='both')\n",
    "    cb.set_label(plot_dict['cb_label'])\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(filepath, dpi=150, bbox_inches='tight')\n",
    "\n",
    "    # Show\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ar_types)",
   "language": "python",
   "name": "ar_types"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
